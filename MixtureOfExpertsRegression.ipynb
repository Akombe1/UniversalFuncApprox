{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Experts Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sample data (x values and corresponding y values)\n",
    "x_data = np.array([0, 1, 2, 3, 4, 5])  # Input x values\n",
    "y_data = np.array([1, 3, 5, 7, 9, 11])  # Output y values (y = 2x + 1)\n",
    "\n",
    "# Number of experts\n",
    "num_experts = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize expert weights (each expert has 2 weights: one for x and one for bias)\n",
    "experts = np.random.randn(num_experts, 2)  # Shape: (3, 2)\n",
    "\n",
    "# Initialize gating network weights (1 weight per expert)\n",
    "gate_weights = np.random.randn(num_experts)\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# Number of training iterations\n",
    "epochs = 100\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))  # Subtract max for numerical stability\n",
    "    return exp_z / np.sum(exp_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0  # Accumulate loss over all training samples\n",
    "\n",
    "    # Accumulate gradients for experts and gating network\n",
    "    grad_experts = np.zeros_like(experts)  # Shape: (3,2)\n",
    "    grad_gate_weights = np.zeros_like(gate_weights)  # Shape: (3,)\n",
    "\n",
    "    for i in range(len(x_data)):\n",
    "        x = x_data[i]\n",
    "        y_true = y_data[i]\n",
    "\n",
    "        # Forward pass\n",
    "        input_vector = np.array([x, 1])  # Bias is 1\n",
    "\n",
    "        # Compute expert predictions (linear regression per expert)\n",
    "        expert_outputs = np.dot(experts, input_vector)  # Shape: (3,)\n",
    "\n",
    "        # Compute gating probabilities\n",
    "        gate_probs = softmax(gate_weights)  # Shape: (3,)\n",
    "\n",
    "        # Compute final output (weighted sum of expert predictions)\n",
    "        y_pred = np.sum(gate_probs * expert_outputs)\n",
    "\n",
    "        # Compute loss (Mean Squared Error)\n",
    "        loss = (y_pred - y_true) ** 2\n",
    "        total_loss += loss\n",
    "\n",
    "        # Compute gradients (Backpropagation)\n",
    "        \n",
    "        # Gradients w.r.t expert weights\n",
    "        for j in range(num_experts):\n",
    "            grad_experts[j] += 2 * (y_pred - y_true) * gate_probs[j] * input_vector\n",
    "\n",
    "        # Gradients w.r.t gating weights\n",
    "        for j in range(num_experts):\n",
    "            grad_gate_weights[j] += 2 * (y_pred - y_true) * (expert_outputs[j] - y_pred) * gate_probs[j] * (1 - gate_probs[j])\n",
    "\n",
    "    # Update expert weights using average gradient\n",
    "    experts -= lr * (grad_experts / len(x_data))\n",
    "\n",
    "    # Update gating network weights using average gradient\n",
    "    gate_weights -= lr * (grad_gate_weights / len(x_data))\n",
    "\n",
    "    # Store average loss per epoch\n",
    "    loss_history.append(total_loss / len(x_data))\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(x_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), loss_history, label=\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
